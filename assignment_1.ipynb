{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GizawAAiT/NLP/blob/main/assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-0fymdVZ2ux"
      },
      "source": [
        "## *Read The Corpus (GPAC)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MIK465qtedu"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "from google.colab import drive\n",
        "import textwrap, string, re\n",
        "\n",
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the corpus path in the drive:\n",
        "corpus_path = '/content/drive/MyDrive/NLP/GPAC.txt'\n",
        "\n",
        "# Open the file and read its content\n",
        "with open(corpus_path, 'r', encoding='utf-8') as file:\n",
        "        # Read the entire content of the file\n",
        "        corpus_content = file.read(10000000)\n",
        "\n",
        "        # Amharic punctuation characters to be removed\n",
        "        amharic_punctuation = \"።፤፥፦፧፨።!;:?,፡'\\\"፣\"\n",
        "\n",
        "        # Create a translation table\n",
        "        translator = str.maketrans('', '', string.punctuation + amharic_punctuation)\n",
        "\n",
        "        # Remove punctuation using the translation table\n",
        "        content_without_punctuation = corpus_content.translate(translator)\n",
        "\n",
        "print(len(content_without_punctuation))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94k3yjXvZC93"
      },
      "source": [
        "# 1.1 Create n-grams for n=1, 2, 3, 4. You can show sample prints.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JdLYl4Kcabsb"
      },
      "outputs": [],
      "source": [
        "class Corpus:\n",
        "  def __init__(self, content):\n",
        "    self.content = content\n",
        "    self.words = self.content.split()\n",
        "    self.uniqueWords = set(self.words)\n",
        "\n",
        "  def set_unigrams(self):\n",
        "    self.oneGrams = self.words\n",
        "\n",
        "  def set_bigrams(self):\n",
        "    self.twoGrams = [(self.words[i], self.words[i+1]) for i in range(len(self.words)-1)]\n",
        "\n",
        "  def set_trigrams(self):\n",
        "    self.threeGrams = [(self.words[i], self.words[i+1], self.words[i+2]) for i in range(len(self.words)-2)]\n",
        "\n",
        "  def set_quadgrams(self):\n",
        "    self.fourGrams = [(self.words[i], self.words[i+1], self.words[i+2], self.words[i+3]) for i in range(len(self.words)-3)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8oBmXS2boe1",
        "outputId": "a4a1ec6f-6683-489f-f5bc-48b4659977e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ምን', 'መሰላችሁ', 'አንባቢያን', 'ኢትዮጵያ', 'በተደጋጋሚ', 'ጥሪው', 'ደርሷት', 'ልትታደመው', 'ያልቻለችው', 'የአለም']\n",
            "[('ምን', 'መሰላችሁ'), ('መሰላችሁ', 'አንባቢያን'), ('አንባቢያን', 'ኢትዮጵያ'), ('ኢትዮጵያ', 'በተደጋጋሚ'), ('በተደጋጋሚ', 'ጥሪው'), ('ጥሪው', 'ደርሷት'), ('ደርሷት', 'ልትታደመው'), ('ልትታደመው', 'ያልቻለችው'), ('ያልቻለችው', 'የአለም'), ('የአለም', 'የእግር')]\n",
            "[('ምን', 'መሰላችሁ', 'አንባቢያን'), ('መሰላችሁ', 'አንባቢያን', 'ኢትዮጵያ'), ('አንባቢያን', 'ኢትዮጵያ', 'በተደጋጋሚ'), ('ኢትዮጵያ', 'በተደጋጋሚ', 'ጥሪው'), ('በተደጋጋሚ', 'ጥሪው', 'ደርሷት'), ('ጥሪው', 'ደርሷት', 'ልትታደመው'), ('ደርሷት', 'ልትታደመው', 'ያልቻለችው'), ('ልትታደመው', 'ያልቻለችው', 'የአለም'), ('ያልቻለችው', 'የአለም', 'የእግር'), ('የአለም', 'የእግር', 'ኳስ')]\n",
            "[('ምን', 'መሰላችሁ', 'አንባቢያን', 'ኢትዮጵያ'), ('መሰላችሁ', 'አንባቢያን', 'ኢትዮጵያ', 'በተደጋጋሚ'), ('አንባቢያን', 'ኢትዮጵያ', 'በተደጋጋሚ', 'ጥሪው'), ('ኢትዮጵያ', 'በተደጋጋሚ', 'ጥሪው', 'ደርሷት'), ('በተደጋጋሚ', 'ጥሪው', 'ደርሷት', 'ልትታደመው'), ('ጥሪው', 'ደርሷት', 'ልትታደመው', 'ያልቻለችው'), ('ደርሷት', 'ልትታደመው', 'ያልቻለችው', 'የአለም'), ('ልትታደመው', 'ያልቻለችው', 'የአለም', 'የእግር'), ('ያልቻለችው', 'የአለም', 'የእግር', 'ኳስ'), ('የአለም', 'የእግር', 'ኳስ', 'ዋ')]\n"
          ]
        }
      ],
      "source": [
        "corpus = Corpus(content_without_punctuation)\n",
        "# Set the n grams (1, 2, 3, 4) for the corpus obj.\n",
        "corpus.set_unigrams()\n",
        "corpus.set_bigrams()\n",
        "corpus.set_trigrams()\n",
        "corpus.set_quadgrams()\n",
        "\n",
        "# print sample\n",
        "print(corpus.oneGrams[:10])\n",
        "print(corpus.twoGrams[:10])\n",
        "print(corpus.threeGrams[:10])\n",
        "print(corpus.fourGrams[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gMKUOAyUD7I"
      },
      "source": [
        "#1.2 Calculate probabilities of n-grams and find the top 10 most likely n-grams for all n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmLLD2WvV7VD",
        "outputId": "1e1b9f3d-e194-4e4b-8ad3-f028878c1a8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('ነው', 0.01743256073430263), ('ላይ', 0.009025516690217424), ('ግን', 0.00496655527366713), ('ወደ', 0.004585709151590916), ('ውስጥ', 0.004584099942624396), ('ነበር', 0.004431225090805072), ('እና', 0.004338963776724637), ('ነገር', 0.003782713877297829), ('ጋር', 0.0036963529960946312), ('ጊዜ', 0.0031814061268084833)]\n",
            "[(('ዓ', 'ም'), 0.0011886696608562125), (('ነገር', 'ግን'), 0.000629737446681044), (('ማለት', 'ነው'), 0.0005246024044753501), (('ብቻ', 'ሳይሆን'), 0.0004934910144348896), (('ብቻ', 'ነው'), 0.00043448665401332677), (('አዲስ', 'አበባ'), 0.00037172747065584625), (('ምን', 'ያህል'), 0.00027356567104542797), (('በአዲስ', 'አበባ'), 0.0002488911203236835), (('ሚሊዮን', 'ዶላር'), 0.00024513629738776585), (('ላይ', 'ነው'), 0.0002354810384096919)]\n",
            "[(('እ', 'ኤ', 'አ'), 0.00016092106928213159), (('2004', 'ዓ', 'ም'), 8.099693820533957e-05), (('ነው', 'ነገር', 'ግን'), 6.973246335559035e-05), (('ወደ', 'አዲስ', 'አበባ'), 5.9540795634388684e-05), (('ቀን', '2004', 'ዓ'), 5.9540795634388684e-05), (('ጠቅላይ', 'ሚኒስትር', 'መለስ'), 5.7931584941567376e-05), (('2005', 'ዓ', 'ም'), 5.524956712019851e-05), (('ቂ', 'ቂ', 'ቂ'), 5.417675999165097e-05), (('ነበር', 'ነገር', 'ግን'), 5.36403564273772e-05), (('ዓ', 'ም', 'ጀምሮ'), 4.7739917220365704e-05)]\n",
            "[(('ቀን', '2004', 'ዓ', 'ም'), 5.7931616020098855e-05), (('ቀን', '2005', 'ዓ', 'ም'), 4.666713512730185e-05), (('ጨዋታን', 'ጨዋታ', 'ያነሳው', 'የለ'), 4.291230816303619e-05), (('የጽንስና', 'ማህጸን', 'ሐኪሞች', 'ማህበር'), 4.023028890284642e-05), (('እንግዲህ', 'ጨዋታን', 'ጨዋታ', 'ያነሳው'), 3.1647827270239187e-05), (('ጠቅላይ', 'ሚኒስትር', 'መለስ', 'ዜናዊ'), 2.1456154081518096e-05), (('የኢትዮጵያ', 'የጽንስና', 'ማህጸን', 'ሐኪሞች'), 2.1456154081518096e-05), (('ቀን', '2003', 'ዓ', 'ም'), 1.7164923265214474e-05), (('የጽንስና', 'ማህጸን', 'ሕክምና', 'እስፔሻሊስት'), 1.2873692448910857e-05), (('በብርሃንና', 'ሰላም', 'ማተሚያ', 'ቤት'), 1.2337288596872905e-05)]\n"
          ]
        }
      ],
      "source": [
        "from heapq import heapify, heappush, heappop\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "def probability(grams):\n",
        "    frequency = Counter(grams)\n",
        "    total = len(grams)\n",
        "    probability = {gram: frequency[gram]/total for gram in grams}\n",
        "    return  probability\n",
        "\n",
        "\n",
        "def top_10_probability(probability):\n",
        "    h = [] #heap:\n",
        "\n",
        "    for gram in probability:\n",
        "      heappush(h, (probability[gram], gram))\n",
        "      if len(h) > 10:\n",
        "        heappop(h)\n",
        "\n",
        "    top_10, total = [], sum(probability.values())\n",
        "    while h:\n",
        "      gram = heappop(h)[1]\n",
        "      top_10.append((gram, probability[gram]/total))\n",
        "\n",
        "\n",
        "    return list(reversed(top_10))\n",
        "\n",
        "# calculate the probability for each n-grams [1, 2, 3, 4]\n",
        "oneGramProb = probability(corpus.oneGrams)\n",
        "twoGramProb = probability(corpus.twoGrams)\n",
        "threeGramProb = probability(corpus.threeGrams)\n",
        "fourGramProb = probability(corpus.fourGrams)\n",
        "\n",
        "# print top 10 probability for each\n",
        "print(top_10_probability(oneGramProb))\n",
        "print(top_10_probability(twoGramProb))\n",
        "print(top_10_probability(threeGramProb))\n",
        "print(top_10_probability(fourGramProb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFtfHivYop6I"
      },
      "source": [
        "# 1.3 What is the probability of the sentence. \"ኢትዮጵያ ታሪካዊ ሀገር ናት \". You can also try\n",
        "more sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5HZ_kpqW4aL",
        "outputId": "fbd5be0a-faa4-4149-a4a7-5026ff7fb020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0001426330052774212\n"
          ]
        }
      ],
      "source": [
        "def probability(sentence, corpus):\n",
        "    freqOneGram, freqTwoGram = Counter(corpus.oneGrams), Counter(corpus.twoGrams)\n",
        "    words = sentence.split()\n",
        "    probability = 1.0\n",
        "\n",
        "    for i in range(len(words)-1):\n",
        "        uni = freqOneGram[words[i]] if words[i] in freqOneGram else 0\n",
        "        bi = freqTwoGram[(words[i], words[i+1])] if (words[i], words[i+1]) in freqTwoGram else 0\n",
        "        probability *= (bi/uni if uni !=0 else 1.0)\n",
        "\n",
        "    return probability\n",
        "\n",
        "prob = probability(\"የተሰረቀ ሰው መጣ\", corpus)\n",
        "print(prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.4 Generate random sentences using n-grams; explain what happens as n-increases\n",
        "based on your output."
      ],
      "metadata": {
        "id": "3YsrJeppV7Zl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wGsX0DmxYG-1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "d66182f2-193e-4627-8f4f-1b985b4eeb95"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ad617106a461>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfreqOneGram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreqTwoGram\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfreqThreeGram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moneGrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwoGrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreeGrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprobabil_bigram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Counter' is not defined"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "freqOneGram, freqTwoGram , freqThreeGram = Counter(corpus.oneGrams), Counter(corpus.twoGrams), Counter(corpus.threeGrams)\n",
        "def probabil_bigram(words):\n",
        "    prob = 1.0\n",
        "    for i in range(len(words)-1):\n",
        "        uni = freqOneGram[words[i]] if words[i] in freqOneGram else 0\n",
        "        bi = freqTwoGram[(words[i], words[i+1])] if (words[i], words[i+1]) in freqTwoGram else 0\n",
        "        prob *= (bi/uni if uni !=0 else 1.0)\n",
        "    return prob\n",
        "\n",
        "def probabil_trigram(words):\n",
        "    prob = 1.0\n",
        "    for i in range(len(words)-2):\n",
        "        bi = freqTwoGram[(words[i], words[i+1])] if (words[i], words[i+1]) in freqTwoGram else 0\n",
        "        tri = freqThreeGram[(words[i], words[i+1], words[i+2])] if (words[i], words[i+1], words[i+2]) in freqThreeGram else 0\n",
        "        prob *= (tri/bi if bi !=0 else 1.0)\n",
        "    return prob\n",
        "\n",
        "\n",
        "\n",
        "def random_sentences(corpus, cnt, length):\n",
        "    # freqOneGram, freqTwoGram = Counter(corpus.oneGrams), Counter(corpus.twoGrams)\n",
        "    sentences = [[random.choice(corpus.words), random.choice(corpus.words)] for _ in range(cnt)]\n",
        "\n",
        "    for _ in range(length-1):\n",
        "        for i in range(cnt):\n",
        "            sufix = ('', 0)\n",
        "            prob = probabil_trigram(sentences[i])\n",
        "            # select from candidates\n",
        "            for candidate in corpus.uniqueWords:\n",
        "                cur_prob = prob * probabil_trigram([sentences[i][-1], candidate])\n",
        "\n",
        "                if cur_prob > sufix[1]:\n",
        "                    sufix = (candidate, cur_prob)\n",
        "\n",
        "            # add the best candidate\n",
        "            sentences[i].append(sufix[0])\n",
        "\n",
        "    return [' '.join(sentence) for sentence in sentences]\n",
        "\n",
        "random_sent = random_sentences(corpus, 4, 20)\n",
        "print(random_sent)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FXn1D_cjqC8d"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}